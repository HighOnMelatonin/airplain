{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "3brax54gc92mdv5yf4bog8",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "# 2D Design Template"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "boi0tuojn2lv0a7psqnphm",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "# Overview\n",
                "\n",
                "The purpose of this project is for you to apply what you have learnt in this course. This includes working with data and visualizing it, create model of linear regression, as well as using metrics to measure the accuracy of your model. \n",
                "\n",
                "Please find the project handout description in the following [link](https://edimension.sutd.edu.sg/webapps/blackboard/content/listContent.jsp?course_id=_5582_1&content_id=_200537_1).\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "4h8s09nq04kexe620dnp0j",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "## Deliverables\n",
                "\n",
                "You need to submit this Jupyter notebook together with the dataset into Vocareum. Use the template in this notebook to work on this project. You are free to edit or add more cells if needed"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "d4oukr61l4snjxaqy2gn3l"
            },
            "source": [
                "## Students Submission\n",
                "*Include a short sentence summarizing each memberâ€™s contribution.*\n",
                "\n",
                "Student's Name:\n",
                "- Teo Li Zhong\n",
                "  - Documented the code and streamlit\n",
                "- Otniel Steven Krisanto\n",
                "  - Scoured data for parameters and documented code\n",
                "- Chew Wei-Han\n",
                "  - Regression Model\n",
                "- Aishaani Pal\n",
                "  - Scoured data for parameters\n",
                "- Tan Rui Anh\n",
                "  - Cleaned and processed raw data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "sugx7cl409ty0kwq55dua"
            },
            "source": [
                "# Airplain\n",
                "\n",
                "## How might we predict how much air pollution a city in the Netherlands will create, and use that data/prediction to help city planners design more sustainable cities to reduce air pollution\n",
                "\n",
                "<strong>User Persona</strong>: Dutch Urban Planners\n",
                "\n",
                "The decision to target the Netherlands is due to the Netherlands being well knowned for urban design, and for future considerations, the predictions can be widened to the rest of the European region.\n",
                "\n",
                "<strong>The Problem</strong>: As countries urbanise, urban planners are tasked with designing and planning cities that are liveable and sustainable. However, it can be difficult to predict how different aspects and factors can affect air pollution in a city, hence Airplain was conceived.\n",
                "\n",
                "Airplain is a linear regression model designed to predict the levels of air pollution (via PM2.5) a city might produce based on a set of parameters.\n",
                "\n",
                "More details on the project structure can be found in the [readme](README.md)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "d88z0vga22yzgsnze3ql",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "## Dataset\n",
                "The dataset used for training the regression model was taken from various official statistics databases from the Netherlands. \n",
                "\n",
                "### Data sources:\n",
                "1. [Netherlands Population density data](https://opendata.cbs.nl/statline/portal.html?_la=nl&_catalog=CBS&tableId=70072ned&_theme=246)\n",
                "2. [Netherlands region code](https://opendata.cbs.nl/statline/#/CBS/nl/dataset/84929NED/table?dl=343E)\n",
                "3. [Netherlands PM2.5 data](https://www.luchtmeetnet.nl/rapportages)\n",
                "4. [Netherlands proximity to facilites](https://opendata.cbs.nl/statline/#/CBS/en/dataset/85560ENG/table?ts=1754288993424)\n",
                "5. [Land use by municipality](https://opendata.cbs.nl/statline/portal.html?_la=en&_catalog=CBS&tableId=70262ENG&_theme=1182)\n",
                "\n",
                "### Processed Data\n",
                "All data were processed and converted in csv format for ease of import into `pandas`, the processed data is formatted in the following format:\n",
                "<table>\n",
                "    <tr>\n",
                "        <td></td>\n",
                "        <td>Year 1</td>\n",
                "        <td>Year 2</td>\n",
                "        <td>Year 3</td>\n",
                "        <td>...</td>\n",
                "    </tr>\n",
                "    <tr>\n",
                "        <td>Region 1</td>\n",
                "        <td>Datapoint 11</td>\n",
                "        <td>Datapoint 12</td>\n",
                "        <td>Datapoint 13</td>\n",
                "        <td>...</td>\n",
                "    </tr>\n",
                "    <tr>\n",
                "        <td>Region 2</td>\n",
                "        <td>Datapoint 21</td>\n",
                "        <td>Datapoint 22</td>\n",
                "        <td>Datapoint 23</td>\n",
                "        <td>...</td>\n",
                "    </tr>\n",
                "    <tr>\n",
                "        <td>...</td>\n",
                "        <td>...</td>\n",
                "        <td>...</td>\n",
                "        <td>...</td>\n",
                "        <td>...</td>\n",
                "    </tr>\n",
                "</table>\n",
                "\n",
                "For datasets that have more than one parameter as a datapoint, the values were stored in a tuple\n",
                "\n",
                "The independent variables that the team has come up with were:\n",
                "1. Land use (Roads vs Parks)\n",
                "2. Population density\n",
                "3. Proximity to jobs (by km)\n",
                "\n",
                "<sub>Each independent variable is stored in it's own csv</sub>\n",
                "\n",
                "The target is:\n",
                "1. PM2.5 value of the municipality\n",
                "\n",
                "More details on the dataset can be found in the [readme](/datafiles/README.md)\n",
                "\n",
                "- Put python codes for loading the data into pandas dataframe(s). The data should be the raw data downloaded from the source. No pre-processing using any software (excel, python, etc) yet. Include this dataset in your submission\n",
                "- Explain each column of your dataset (can use comment or markdown)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "cellIdentifier": "ud3vpqunu1qpn45nwknjjd"
            },
            "outputs": [
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mRunning cells with 'Python 3.11.7' requires the ipykernel package.\n",
                        "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
                        "\u001b[1;31mCommand: 'c:/msys64/ucrt64/bin/python.exe -m pip install ipykernel -U --user --force-reinstall'"
                    ]
                }
            ],
            "source": [
                "import linearRegression\n",
                "import cleanNether\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.axes as axes"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "mnalotvuhwah3o3d16kul",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "### Clean & Analyze your data\n",
                "Use python code to:\n",
                "- Clean your data\n",
                "- Calculate Descriptive Statistics and other statistical analysis\n",
                "- Visualization with meaningful analysis description"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "cellIdentifier": "drintkqv74g03a98h37kr7a"
            },
            "outputs": [],
            "source": [
                "## Process all the data and output to a csv format\n",
                "print(\"Population Density Data Processed:\", cleanNether.popDensity())\n",
                "print(\"Proximity Data Processed:\", cleanNether.trimProximity())\n",
                "print(\"Land Use Data Processed:\", cleanNether.landUse())\n",
                "print(\"Travel Data Processed:\", cleanNether.carTravel())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "cellIdentifier": "llzyf0wxva9qcb5sqwe4ip"
            },
            "outputs": [],
            "source": [
                "# descriptive statistics\n",
                "## Five number summary\n",
                "print(\"Five number summary:\", cleanNether.getFiveNumberSummary())\n",
                "\n",
                "popDensityDF: pd.DataFrame = pd.read_csv('datafiles/processedPopDensity.csv',index_col=0).fillna(-1)\n",
                "# pmDF: pd.DataFrame = pd.read_csv('datafiles/processedPm2.5.csv',index_col=0).fillna(-1)\n",
                "proximityDF: pd.DataFrame = pd.read_csv('datafiles/processedProximity.csv')\n",
                "landUseDF: pd.DataFrame = pd.read_csv('datafiles/processedLandUse.csv',sep=\";\",index_col=0).fillna(-1) \n",
                "transportPublicDF: pd.DataFrame = pd.read_csv('datafiles/processedCarTravelPublic.csv')\n",
                "transportPrivateDF: pd.DataFrame = pd.read_csv('datafiles/processedCarTravelPrivate.csv')\n",
                "\n",
                "def getDataFromDF(df: pd.DataFrame, region: str, year: str, targetCol: str) -> str:\n",
                "    '''\n",
                "    Descripton.\n",
                "    \n",
                "    Args:\n",
                "        some_arg (Any):\n",
                "    \n",
                "    Returns:\n",
                "        Any:\n",
                "    \n",
                "    Functionality\n",
                "        - does a thing\n",
                "    \n",
                "    Raises:\n",
                "        AssertionError:\n",
                "    '''\n",
                "    #print(f'{region=}, {type(region)=}, {year=}, {type(year)=}')\n",
                "    #print(year, type(year))\n",
                "    year = int(year)\n",
                "    regionMatches: pd.Series = df[\"Region\"] == region\n",
                "    yearMatches: pd.Series = df[\"Year\"] == year\n",
                "    regionMatches: set = set(df.index[regionMatches].tolist())\n",
                "    yearMatches: set = set(df.index[yearMatches].tolist())\n",
                "    desiredIndices: set = regionMatches & yearMatches\n",
                "    #print(f'{len(regionMatches)=}, {len(yearMatches)=}')\n",
                "    #print(f'{len(desiredIndices)=}')\n",
                "    assert len(desiredIndices) == 1\n",
                "    desiredIndex: int = list(desiredIndices)[0]\n",
                "    targetIndex: int = df.columns.get_loc(targetCol)\n",
                "\n",
                "    output = df.iloc[desiredIndex,targetIndex]\n",
                "    return output\n",
                "  "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "cellIdentifier": "pvcupguct9c8fggigcezh"
            },
            "outputs": [],
            "source": [
                "# visualization with analysis\n",
                "features = ['Population Density', 'Total Road Area', 'Total Greenery Area','Public Transport Travel','Private Transport Travel']\n",
                "\n",
                "for feature in features:\n",
                "    plt.scatter(dataFeaturesTest[feature], dataTarget_test)\n",
                "    plt.scatter(dataFeaturesTest[feature], pred)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "5spy1s2ji3345y1uunm7es",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "### Features and Target Preparation\n",
                "\n",
                "Prepare features and target for model training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "cellIdentifier": "x1leu6b5aph6akcqy9stf4",
                "collapsed": true,
                "jupyter": {
                    "outputs_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# put Python code to prepare your features and target\n",
                "#Merge the cleaned data into 1 dataframe\n",
                "newColumns: pd.DataFrame = pd.DataFrame(columns=['Population Density', 'Total Road Area', 'Total Greenery Area','Public Transport Travel','Private Transport Travel'])\n",
                "for index, row in proximityDF.iterrows():\n",
                "    region: str = row['Region']\n",
                "    year: str = str(row['Year'])\n",
                "\n",
                "    #Process population density\n",
                "    try:\n",
                "        popDensity: float = popDensityDF.loc[region,year]\n",
                "        \n",
                "    except:\n",
                "        popDensity: float = -1.0\n",
                "\n",
                "    #Process land use\n",
                "    try:\n",
                "        roadArea: float | str; greenArea: float\n",
                "        value = landUseDF.loc[region, year]\n",
                "        assert value != -1.0\n",
                "        value = value.replace(\"(\",\"\").replace(\")\",\"\").replace('\\'','')\n",
                "        roadArea, greenArea = value.split(\",\")\n",
                "        roadArea = float(roadArea)\n",
                "        greenArea = float(greenArea)\n",
                "    except:\n",
                "        roadArea: float = -1.0\n",
                "        greenArea: float = -1.0\n",
                "\n",
                "    #Process travel data\n",
                "    try:\n",
                "        publicTransport: float = float(getDataFromDF(transportPublicDF,region,year, 'Public Transport in km'))\n",
                "        #print('found')\n",
                "    except:\n",
                "        publicTransport: float = -1.0\n",
                "    try:\n",
                "        privateTransport: float = float(getDataFromDF(transportPrivateDF,region,year, 'Private Transport in km'))\n",
                "        #print('found')\n",
                "    except:\n",
                "        privateTransport: float = -1.0\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "wyzlafckek8h4t0nsibxr",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "### Building Model\n",
                "\n",
                "Use python code to build your model. Give explanation on this process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "cellIdentifier": "nkl339hcc1g22vccuogg2o",
                "collapsed": true,
                "jupyter": {
                    "outputs_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# put Python code to build your model\n",
                "mergedDF: pd.DataFrame = pd.concat([proximityDF,newColumns],axis=1)\n",
                "print(mergedDF)\n",
                "mergedDF.to_csv('compiledData.csv',index=False)\n",
                "\n",
                "print('-'*150)\n",
                "#Remove incomplete rows from the data to get the final compiled dataset\n",
                "incompleteRows: list = []\n",
                "for index, row in mergedDF.iterrows():\n",
                "    complete: bool = True\n",
                "    # '0 to 10 km','>10 to 20 km','>20 to 50km', 'Population Density','Total Road Area','Total Greenery Area', 'Public Transport Travel', 'Private Transport Travel' For testing\n",
                "    exclusionList : list[str] = [ 'Public Transport Travel'] #For testing\n",
                "    for key, value in row.items():\n",
                "        if key in exclusionList: #For testing\n",
                "            continue #For testing\n",
                "        if value == -1.0:\n",
                "            complete: bool = False\n",
                "            break\n",
                "    if not complete:\n",
                "        incompleteRows.append(index)\n",
                "data: pd.DataFrame = mergedDF.drop(incompleteRows, axis=0).reset_index()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "2unt7l8s45pvvfr8i0j0ka",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "### Evaluating the Model\n",
                "\n",
                "- Describe the metrics of your choice\n",
                "- Evaluate your model performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "cellIdentifier": "0pc6mmhipg0b5twb6ag1td"
            },
            "outputs": [],
            "source": [
                "# put Python code to test & evaluate the model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "hnrervpc9ood1trkd0ku3c",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "### Improving the Model\n",
                "\n",
                "- Improve the models by performing any data processing techniques or hyperparameter tuning.\n",
                "- You can repeat the steps above to show the improvement as compared to the previous performance\n",
                "\n",
                "Note:\n",
                "- You should not change or add dataset at this step\n",
                "- You are allowed to use library such as sklearn for data processing (NOT for building model)\n",
                "- Make sure to have the same test dataset so the results are comparable with the previous model \n",
                "- If you perform hyperparameter tuning, it will require you to split your training data further into train and validation dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "cellIdentifier": "x3anvx5y9u9s2x85i5gnwa"
            },
            "outputs": [],
            "source": [
                "# Re-iterate the steps above with improvement"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "c9ywqckb64avu5qr8n5i2",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "### Discussion and Analysis\n",
                "\n",
                "- Analyze the results of your metrics.\n",
                "- Explain how does your analysis and machine learning help to solve your problem statement.\n",
                "- Conclusion"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "8pdxldawaydxaekkynrcgk"
            },
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
